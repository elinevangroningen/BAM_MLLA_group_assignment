---
title: "R code for Lasso Regularized Regression"
output: html_notebook
---
## Linear Lasso Reqularized Regression Model

In this section, regularized regression model will be speficied and trained. Lasso penalty is chosen to simultaneously perform subset selection. 
Therefore, mixture is set to 1 in the model specification. 

## Model specification
Specification of lasso-regularized logistic regression model, where the penalty parameter will be tuned:
```{r, message=FALSE}
lasso_linreg <- linear_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")

#check that model specified correctly:
lasso_linreg %>% translate()
```

## Preprocessing recipe
In this section, the recipe is formulated. All the variables included in the final dataset are included in the recipe, in order to perform the subset selection through the lasso penalty. As the property type and bed type have some categories with just a few observations, the categories that include less than 1% of the total number of observations are combined to "other" category to avoid sparse data. Additionally, dummies are created for all of the nominal variables. Lastly, all the variables are normalized.

```{r}
lasso_recipe <-  recipe(price ~ ., 
                          data = data_train) %>% 
                        update_role(id, new_role = "ID") %>%
                        step_other(property_type, bed_type,  threshold = 0.01, other = "other values") %>% 
                        step_dummy(all_nominal(), -all_outcomes()) %>%
                        step_normalize(all_predictors(), -all_outcomes())

lasso_recipe
```

Testing that this works properly:
```{r}
data_baked <- lasso_recipe %>% prep(data_train) %>% bake(data_train)
head(data_baked)
```

# Create Lasso Workflow
```{r message = FALSE}
lasso_wf <- workflow() %>% 
  add_recipe(lasso_recipe) %>% 
  add_model(lasso_linreg)
lasso_wf
```

## Tuning grids
Next, the $\lambda$ parameter of the lasso model will be tuned. For that purpose, a tuning grid is specified. 
```{r}
grid_lasso <- tibble(penalty = 10^(seq(from = -5, to = 1, length.out = 70)))
```

## Tuning lasso-penalized linear regression
10-k-cross-validation is used to tune the lasso-penalized linear regression:
```{r}
lasso_tune <- lasso_wf %>% 
  tune_grid(resamples = data_folds, 
            grid = grid_lasso,
            metrics = metric_set(mae, rmse, rsq_trad))
```

Plot the metrics against lambda:
```{r}
lasso_tune_metrics <- lasso_tune %>% 
  collect_metrics()
lasso_tune_metrics %>% filter(.metric == "rmse") %>% 
  ggplot(aes(x = penalty, y = mean, 
             ymin = mean - std_err, ymax = mean + std_err)) + 
  geom_linerange(alpha = 0.5) + 
  geom_point() + 
  scale_x_log10() + 
  labs(y = "RMSE", x = expression(lambda))

lasso_tune_metrics %>% filter(.metric == "rsq_trad") %>% 
  ggplot(aes(x = penalty, y = mean, 
             ymin = mean - std_err, ymax = mean + std_err)) + 
  geom_linerange(alpha = 0.5) + 
  geom_point() + 
  scale_x_log10() + 
  labs(y = "rsq_trad", x = expression(lambda))

lasso_tune_metrics %>% filter(.metric == "mae") %>% 
  ggplot(aes(x = penalty, y = mean, 
             ymin = mean - std_err, ymax = mean + std_err)) + 
  geom_linerange(alpha = 0.5) + 
  geom_point() + 
  scale_x_log10() + 
  labs(y = "mae", x = expression(lambda))
```

Next, the Lambda value which results in best model performance on the train set is selected. It can be seen that as the RMSE is more sensitive for large residuals, the std errors of this metrics are larger compared to the standard errors of mean absolute error (mae). Therefore, mean absolute error is used to select the best model. 
```{r}
lasso_tune %>% show_best("mae")
```

The best model is selected using the one standard error rule, where the simplest model that has mae inside one standard error from the absolute best model is chosen to avoid overfitting.
```{r}
lasso_1se_model <- select_by_one_std_err(lasso_tune, metric = "mae", desc(penalty))
lasso_1se_model
```
As can be seen, the best model has penalty parameter of 0.00496.

Finalize the workflow:
```{r}
lasso_wf_tuned <- 
  lasso_wf %>% 
  finalize_workflow(lasso_1se_model)
lasso_wf_tuned
```
```{r}
lasso_last_fit <- lasso_wf_tuned %>% 
  last_fit(data_split, metrics = metric_set(mae, rmse, rsq_trad))
```

The performance on the test set for this model is:
```{r}
lasso_test_metrics <- lasso_last_fit %>% collect_metrics()
lasso_test_metrics
```

To assess the importance of the predictor variables, model parameter estimates are calculated below:
```{r}
lasso_wf_tuned %>% fit(data_train) %>% pull_workflow_fit() %>% tidy() 
```
As lasso performs subset selection automatically, some variables have coefficient of zero. There is multiple variables with coefficient of zero, which implies that these variables are less important for the price prediction of new Airbnb listing. The most important variables can be identified by looking at the coefficients as well, and the 4 most important variables are number of accommodates, the number of days that the airbnb is available inside 30 days, room type of entire home apartment, and lastly, Centrum-West neighbourhood.

# Assessment metrics

```{r}
# Generate predicted values for sales
lasso_test_preds <- 
  lasso_wf_tuned %>% 
  fit(data = data_train) %>%
  predict(data_test) %>% 
  pull(.pred)

# Create tibble for distribution plot
lasso_pred <- 
  tibble(observed = data_test$price, 
         predicted = lasso_test_preds, 
         residual = observed - predicted)

# Plot distribution residuals
lasso_residual_plot <- 
  lasso_pred %>% 
  ggplot(aes(x = residual)) +
  geom_density(bw = 0.15, fill = "springgreen", alpha = 0.5) +
  geom_rug() +
  labs(title = "Lasso Regularized Regression Distribution Residuals") +
  theme(plot.title = element_text(hjust = 0.5)) 
lasso_residual_plot

# Save plot for presentation
ggsave("lasso_residual.png", plot = lasso_residual_plot)
```




---
title: "RF"
author: "Kylian van Noordenne"
date: "22-11-2020"
output: html_document
---

# Packages 
```{r libraries }
library(ranger)
library(doParallel)
library(themis)
library(tibble)
library(vip)
```

# Recipe
Within this section, a random forest will be created. First a preprocessing recipe is created. 
The id variable is updated to a seperate role, instead of being a predictor. 
```{r Recipe}
rf_recipe <- recipe(price ~ ., data = data_train) %>%
  update_role(id, new_role = "id var")

rf_recipe
```

# Specify the random forest
Within this section the tune specificaiton are mentioned. The *mtry* is the number of features that are used at each split. THe exact mtry value will be tuned later on. Different values for trees where tested (200, 500 & 1000). Increasing the amount of trees did not have much impact on the results. Therefore, a tree size of 200 is chosen to save computational time. 
```{r Specify}
# Tune specification
tune_spec <- rand_forest(mtry = tune(), trees = 200) %>%
  set_engine("ranger") %>%
  set_mode("regression")
```

# Workflow creation for tuning
Combine the recipe and the model into a workflow that can be tuned.
```{r Workflow}
# Workflow creation
tune_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(tune_spec)
```

A metric set that calculates the *Root Mean Square Error (rmse)*, *the Mean Absolute Error (mae)* and the *R-squared (rsq_trad)* is created. 
```{r Class metrics}
# Class metrics specification 
class_metrics <- metric_set(rmse, mae, rsq_trad)
```

The command bellow allows us to do computations in parallel.
```{r Parallel}
registerDoParallel()
```

The tune grid was initially not optmised, but the command grid = tibble(mtry = 1:34) was utlised. This command checked all the variables. Based on the MAE criteria, a mtry of 6, 7, 8, 9 & 10 was found as the optimal solution. After this finding, these optimal mtry values were taken as mtryinput to save computational time.  
```{r Tune grid}
# Define the tune grid 
tunegrid <- tibble(mtry = c(6, 7, 8, 9, 10))
```

```{r Grid}
# Tune the grid
set.seed(12345)
tune_res <- tune_grid(
  tune_wf,
  resamples = data_folds,
  grid = tunegrid,
  metrics = class_metrics
)
tune_res
```

# Selecting tuning parameters 
```{r Collect metrics}
# Collect metrics
tune_res %>%
  collect_metrics()
```
A plot for finding the best mtry, based on the criteria of the mae. A lower mae would indicate a better results, as a lower value indicates a lower error of prediction. 
```{r Plot MAE}
# Plot the MAE based
tune_res %>%
  collect_metrics() %>%
  filter(.metric == "mae") %>% 
  ggplot(aes(x = mtry, y = mean, ymin = mean - std_err, ymax = mean + std_err)) +
  geom_errorbar() + 
  geom_line() +
  geom_point() +
  labs(y = "mae")
```

This command allows will show the best mtry based on the MAE criteria. However, initially it showed 6, 9, 14, 15 and 20. THerefore, these values are shown again as the grid is limited to only using those optimal mtry values.  
```{r Best MAE}
# Find the mtry with the best MAE
tune_res %>% show_best("mae")
```

# Best model selection

The best model based on the MAE criteria is selected and eventually finalises into the workflow. 
```{r Best model}
# Best model selection
best_rmse <- select_best(tune_res, "mae")
final_rf <- finalize_workflow(tune_wf, best_rmse)
final_rf
```

# Test set performance

Now we can train the finalized workflow on our entire training rest
```{r }
# Finalise workflow on training set
final_res <- final_rf %>%
  last_fit(data_split, metrics = class_metrics)
```

The results based on the test set will be 
```{r }
# Score on test data
set.seed(54321)
final_res %>%
  collect_metrics()
```

# Variable importance 

Now we try to asses the variable importance. We will refit the model based on our previous tune parameters. 
```{r }
# Refit the model
rf_model_vi <- rand_forest(mtry = 6, trees = 200) %>%
  set_engine("ranger", importance = "permutation")

rf_vi_wf <- workflow() %>% 
  add_model(rf_model_vi) %>% 
  add_recipe(rf_recipe)

# Fit the model again
set.seed(12345)
rf_vi_fit <- rf_vi_wf %>% fit(data = data_train)
```

We can use the refitted model in order the gather the variable importance 
```{r }
# Variable importance 
rf_vi_fit %>% pull_workflow_fit() %>% vi()
```
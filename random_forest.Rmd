---
title: "RF"
author: "Kylian van Noordenne"
date: "22-11-2020"
output: html_document
---

Within this section, a random forest will be created. FIrst a preprocessing recipe is created. 

```{r libraries }
library(ranger)
library(doParallel)
library(themis)
```


```{r Basic RF}
library(randomForest)
rf <- randomForest(price ~ bedrooms + beds + host_identity_verified + guests_included + extra_people + pool, data = data_train)
rf

```


```{r Importance} 
# Variable importance plot
varImpPlot(rf)
```



```{r Trees} 
# Random forest plot
plot(rf)
```

Setting up a recipe. The id variable is uptaded to a seperate role, instead of being a predictor. 
```{r Recipe}
rf_recipe <- recipe(price ~ ., data = data_train) %>%
  update_role(id, new_role = "id var")

rf_recipe
```

As the previous plot shows, there is not much decrease in after a certain threshold. In order to save computational time, we specify a random forest with 100 trees
```{r Specify}
# Tune specification
tune_spec <- rand_forest(mtry = tune(), trees = 100) %>%
  set_engine("ranger")
```

Combine the recipe and the model into a workflow that can be tuned.
```{r Workflow}
# Workflow creation
tune_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(tune_spec)
```

We create a metric set that calculates the Root Mean Square Error (rmse), the Mean Absolute Error (mae) and the R-squared (rsq_trad)
```{r Class metrics}
class_metrics <- metric_set(rmse, mae, rsq_trad)
```

The command bellow allows us to do computations in parallel
```{r Parallel}
registerDoParallel()
```


```{r Tune Grid}
# Tune the grid
set.seed(12345)
tune_res <- tune_grid(
  tune_wf,
  resamples = data_folds,
  grid = 10,
  metrics = class_metrics
)
tune_res
```

```{r Collect metrics}
tune_res %>%
  collect_metrics()
```
A plot for finding the best mtry, based on the criteria of the mae. A lower mae would indicate a better results, as a lower value indicates a lower error of prediction. 
```{r Plot MAE}
tune_res %>%
  collect_metrics() %>%
  filter(.metric == "mae") %>% 
  ggplot(aes(x = mtry, y = mean)) +
  geom_line() +
  geom_point() +
  labs(y = "mae")
```

This command allows me to see the best predictions based on the MAE criteria. 
```{r Best MAE}
tune_res %>% show_best("mae")
```
Now select the best model based on the mae criteria
```{r Best model}
best_rmse <- select_best(tune_res, "mae")
final_rf <- finalize_workflow(tune_wf, best_rmse)
final_rf
```

Now we can train the finalized workflow on our entire training rest
```{r }
# Finalise workflow on training set
final_res <- final_rf %>%
  last_fit(data_split, metrics = class_metrics)
```

The results based on the test set will be 
```{r }
# Score on test data
final_res %>%
  collect_metrics()
```

```{r }

```

```{r }

```